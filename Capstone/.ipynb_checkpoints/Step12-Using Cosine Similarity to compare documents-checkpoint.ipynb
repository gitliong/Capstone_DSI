{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "import seaborn as sns\n",
    "cvec = CountVectorizer(stop_words = stop_words.ENGLISH_STOP_WORDS)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = ['000', '01', '06', '08','10254', '12', '15',\n",
    "                   '19', '2018', '22', '25', '28', '45', '500',\n",
    "                   'cox', 'norfolk', 'apply', 'com', 'www', 'applications', 'application',\n",
    "                   'applicants', 'southern', 'https', 'ia', 'var', 'indeedapply', 'env',\n",
    "                   'atlanta', 'opportunity', 'iip', 'gender', 'location', 'new', 'employer',\n",
    "                   'midtown', 'manheim', 'ml', 'including', 'llc', 'truck', 'automotive', 'nationality', \n",
    "                   'nation', 'iot', 'kelley', 'hopea', 'date', 'incadea', 'honeywell', '100', '1372', '27', '300',\n",
    "                   '30308', '30309', '59', '60', '666', '715', '800', '850', '89', '90', 'ga', 'geo', 'genetic',\n",
    "                    'mercedes', 'marta', 'lunch', 'familimarity', 'fitting', 'floors', 'furthermore', 'living', \n",
    "                    'make', 'members', 'family', 'req149533', 'requisition', 'freshman', 'sophomore', 'et', 'etc',\n",
    "                    'etl', 'job', 'invest', 'member', 'eye', 'relocation', 'Unnamed', 'wework', 'yarn', 'yrs',\n",
    "                    'test', 'intent', 'intermediete', 'key', 'inflection', 'informatica', 'way', 'recent', 'fewer',\n",
    "                    'iteratively', 'joining', 'd3', 'bi', 'bs', 'alteryx', 'benz', 'ai', 'arcgis', 'talend', 'al',\n",
    "                    'bus', 'cassandra', 'growing', 'growth', 'guidance', 'bigdata', 'bigquery', 'cotiviti', \n",
    "                    'councils', 'like', 'located', 'devops', 'usa', 'winning', 'ex', 'awesome', 'address', \n",
    "                    'assurance', 'pig', 'needed', 'id', 'integral', 'impeccable', 'arts', 'auditing', 'community',\n",
    "                    'commuter', 'jobs', 'help', 'js', 'human', 'variety', 'stipend', 'rewards', 'sharting', \n",
    "                    'daimler', 'degreepreferred', 'advisors', 'characteristics', 'draw', 'donor', 'creek', 'dental',\n",
    "                    'medical', 'survival', '0064382_p0223181', '10', '1553', '2016', '24', '30327', '401',\n",
    "                    'experiencepredictive', 'emory', 'caffe2', 'caffe', 'workingmother','000', '01', '06', '08','10254', '12', '15',\n",
    "                    '19', '2018', '22', '25', '28', '45', '500',\n",
    "                    'cox', 'norfolk', 'apply', 'com', 'www', 'applications', 'application',\n",
    "                    'applicants', 'southern', 'https', 'ia', 'var', 'indeedapply', 'env',\n",
    "                    'atlanta', 'opportunity', 'iip', 'gender', 'location', 'new', 'employer',\n",
    "                    'midtown', 'manheim', 'ml', 'including', 'llc', 'truck', 'automotive', 'nationality', \n",
    "                    'nation', 'iot', 'kelley', 'hopea', 'date', 'incadea', 'honeywell', '100', '1372', '27', '300',\n",
    "                    '30308', '30309', '59', '60', '666', '715', '800', '850', '89', '90', 'ga', 'geo', 'genetic',\n",
    "                    'mercedes', 'marta', 'lunch', 'familimarity', 'fitting', 'floors', 'furthermore', 'living', \n",
    "                    'make', 'members', 'family', 'req149533', 'requisition', 'freshman', 'sophomore', 'et', 'etc',\n",
    "                    'etl', 'job', 'invest', 'member', 'eye', 'relocation', 'Unnamed', 'wework', 'yarn', 'yrs',\n",
    "                    'test', 'intent', 'intermediete', 'key', 'inflection', 'informatica', 'way', 'recent', 'fewer',\n",
    "                    'iteratively', 'joining', 'd3', 'bi', 'bs', 'alteryx', 'benz', 'ai', 'arcgis', 'talend', 'al',\n",
    "                    'bus', 'cassandra', 'growing', 'growth', 'guidance', 'bigdata', 'bigquery', 'cotiviti', \n",
    "                    'councils', 'like', 'located', 'devops', 'usa', 'winning', 'ex', 'Location'\n",
    "                   ]\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stop = list(stop_words.ENGLISH_STOP_WORDS)\n",
    "\n",
    "new_stop.extend(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    \"\"\"Takes 2 vectors a, b and returns the cosine similarity according \n",
    "    to the definition of the dot product\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(file):\n",
    "    raw = open(file).read()\n",
    "    tokens = word_tokenize(raw)\n",
    "    words = [w.lower() for w in tokens]\n",
    "    \n",
    "    porter = nltk.PorterStemmer()\n",
    "    stemmed_tokens = [porter.stem(t) for t in words]\n",
    "    \n",
    "   \n",
    "    stop_words = new_stop\n",
    "    filtered_tokens = [w for w in stemmed_tokens if not w in stop_words]\n",
    "    \n",
    "    \n",
    "    count = nltk.defaultdict(int)\n",
    "    for word in filtered_tokens:\n",
    "        count[word] += 1\n",
    "    return count;\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between the two documents you are comparing is 0.8065228567560613\n",
      "Similarity between the two documents you are comparing is 0.8079171338005364\n",
      "Similarity between the two documents you are comparing is 0.9987845258190419\n",
      "Similarity between the two documents you are comparing is 0.6315853983031121\n",
      "Similarity between the two documents you are comparing is 0.6316388322991382\n",
      "Similarity between the two documents you are comparing is 0.8055286724386033\n",
      "Similarity between the two documents you are comparing is 0.8076833378221363\n",
      "Similarity between the two documents you are comparing is 0.6564816339166467\n",
      "Similarity between the two documents you are comparing is 0.660643347235352\n",
      "Similarity between the two documents you are comparing is 0.6860503107469159\n",
      "Similarity between the two documents you are comparing is 0.688635923016198\n",
      "Similarity between the two documents you are comparing is 0.8140338226069609\n",
      "Similarity between the two documents you are comparing is 0.8165810849626255\n",
      "Similarity between the two documents you are comparing is 0.8201789974145953\n",
      "Similarity between the two documents you are comparing is 0.8239731688629781\n",
      "Similarity between the two documents you are comparing is 0.7570482531688368\n",
      "Similarity between the two documents you are comparing is 0.7601716945351928\n",
      "Similarity between the two documents you are comparing is 0.8177815169243203\n",
      "Similarity between the two documents you are comparing is 0.8205202283817908\n",
      "Similarity between the two documents you are comparing is 0.606415644140976\n",
      "Similarity between the two documents you are comparing is 0.6111744432757311\n",
      "Similarity between the two documents you are comparing is 0.8326277318524093\n",
      "Similarity between the two documents you are comparing is 0.841112879019486\n",
      "Similarity between the two documents you are comparing is 0.9287453705673209\n",
      "Similarity between the two documents you are comparing is 0.9285662367186911\n",
      "Similarity between the two documents you are comparing is 0.8926826040278204\n",
      "Similarity between the two documents you are comparing is 0.8960227368052309\n",
      "Similarity between the two documents you are comparing is 0.6484136736534301\n",
      "Similarity between the two documents you are comparing is 0.6528088677186586\n",
      "Similarity between the two documents you are comparing is 0.8433042106515983\n",
      "Similarity between the two documents you are comparing is 0.846748787338342\n",
      "Similarity between the two documents you are comparing is 0.8190264332888443\n",
      "Similarity between the two documents you are comparing is 0.8230233873692188\n",
      "Similarity between the two documents you are comparing is 0.8674786321849108\n",
      "Similarity between the two documents you are comparing is 0.8702017212302087\n"
     ]
    }
   ],
   "source": [
    "def get_similarity(dict1, dict2):\n",
    "    all_words_list = []\n",
    "    for key in dict1:\n",
    "        all_words_list.append(key)\n",
    "    for key in dict2:\n",
    "        all_words_list.append(key)\n",
    "    all_words_list_size = len(all_words_list)\n",
    "    \n",
    "    v1 = np.zeros(all_words_list_size, dtype = np.int)\n",
    "    v2 = np.zeros(all_words_list_size, dtype = np.int)\n",
    "    i = 0\n",
    "    for (key) in all_words_list:\n",
    "        v1[i] = dict1.get(key, 0)\n",
    "        v2[i] = dict2.get(key, 0)\n",
    "        i = i + 1\n",
    "    return cos_sim(v1, v2);\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dict1 = process('Bullets')\n",
    "    dict2 = process('Updated_Resume_Vectorized.csv')\n",
    "    dict3 = process('Resume_Vectorized.csv')\n",
    "    dict4 = process('Paragraphs')\n",
    "    dict5 = process('TruckIT-Desc.csv')\n",
    "    dict6 = process('Cotiviti.csv')\n",
    "    dict7 = process('HomeDepot.csv')\n",
    "    dict8 = process('Honeywell.csv')\n",
    "    dict9 = process('AnswerRocket.csv')\n",
    "    dict10 = process('Hope Research.csv')\n",
    "    dict11 = process('Cox.csv')\n",
    "    dict12 = process('Equifax.csv')\n",
    "    dict13 = process('Travelport.csv')\n",
    "    dict14 = process('CocaCola.csv')\n",
    "    dict15 = process('SalesLoft.csv')\n",
    "    dict16 = process('Softvision.csv')\n",
    "    dict17 = process('Aarons.csv')\n",
    "    dict18 = process('InspireBrands.csv')\n",
    "    dict19 = process('Hiscox.csv')\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict1, dict2))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict1, dict3))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict3))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict4))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict4))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict5))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict5))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict6))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict6))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict7))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict7))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict8))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict8))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict9))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict9))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict10))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict10))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict11))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict11))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict12))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict12))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict13))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict13))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict14))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict14))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict15))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict15))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict16))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict16))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict17))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict17))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict18))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict18))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict19))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
