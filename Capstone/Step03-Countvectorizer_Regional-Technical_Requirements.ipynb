{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cvec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Para = pd.read_csv('Paragraphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyzing, processing, evaluating and document...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Identifying/developing appropriate machine lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prototyping tools and techniques to solve comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Developing data driven models to quantify the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Applying, modifying and inventing algorithms t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Validating entity resolution and linking capab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Conducting ROI and benefit analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Documenting and presenting process and perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3-5 Years' Experience in SQL/HiveQL, Python, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Experienced with advanced entity techniques an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bachelor's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist jobs in Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jobs at Equifax in Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist salaries in Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Curious: You enjoy peeling apart a problem and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Creative: You constantly invent and try new ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Practical: You explore theories with an eye to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Focused: You're intent on designing and testin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Determined: You will have both the challenge a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Function as Data Scientist which carries the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Participate in product development with leader...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Define the software architecture of the growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MS or PhD. Degree in relevant discipline (Math...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3+ years’ experience in advanced analytics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3+ years’ experience in a data architecture ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Experience delivering solutions in an Agile en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Working knowledge of the Hadoop ecosystem (inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Proficiency in fully architecting and executin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Proficiency with Node.js and SQL; Expert profi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Experience in machine learning, artificial int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Experience building and optimizing ‘big data’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>Experience performing root cause analysis on i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>Strong analytic skills related to working with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Build processes supporting data transformation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>A successful history of manipulating, processi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>Experience supporting and working with cross-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Proficient understanding of distributed comput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>Develop and update test plans, procedures and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Execute developed test procedures and document...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Technically coordinate with a cross-functional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Maintain and create test scripts, files and da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Work in an integrated product team and underst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>Utilize existing system specifications, interf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Ensure that all technical work is performed an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>Develop test estimates for proposed work and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>A Bachelor's degree in Computer Science, Elect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>Experience in test engineering processes and m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Manual, ad hoc, black and white box testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>Strong collaboration, organization, teaming an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>Ability to work well individually or in a grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>Ability to work under pressure and time constr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>Ability to create and deliver technical presen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>Python or similar scripting language.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>Experience with MIL-STD-1553 data bus, avionic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>Experience with system security and safety eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>Experience with configuration management and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>Experience directing small teams of employees ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>Test Engineer jobs in Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>Jobs at Georgia Tech Research Institute in Atl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>Test Engineer salaries in Atlanta, GA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0    Analyzing, processing, evaluating and document...\n",
       "1    Identifying/developing appropriate machine lea...\n",
       "2    Prototyping tools and techniques to solve comp...\n",
       "3    Developing data driven models to quantify the ...\n",
       "4    Applying, modifying and inventing algorithms t...\n",
       "5    Validating entity resolution and linking capab...\n",
       "6                  Conducting ROI and benefit analysis\n",
       "7    Documenting and presenting process and perform...\n",
       "8    3-5 Years' Experience in SQL/HiveQL, Python, S...\n",
       "9    Experienced with advanced entity techniques an...\n",
       "10                                   Bachelor's Degree\n",
       "11                  Data Scientist jobs in Atlanta, GA\n",
       "12                      Jobs at Equifax in Atlanta, GA\n",
       "13              Data Scientist salaries in Atlanta, GA\n",
       "14   Curious: You enjoy peeling apart a problem and...\n",
       "15   Creative: You constantly invent and try new ap...\n",
       "16   Practical: You explore theories with an eye to...\n",
       "17   Focused: You're intent on designing and testin...\n",
       "18   Determined: You will have both the challenge a...\n",
       "19   Function as Data Scientist which carries the e...\n",
       "20   Participate in product development with leader...\n",
       "21   Define the software architecture of the growin...\n",
       "22   MS or PhD. Degree in relevant discipline (Math...\n",
       "23         3+ years’ experience in advanced analytics.\n",
       "24   3+ years’ experience in a data architecture ro...\n",
       "25   Experience delivering solutions in an Agile en...\n",
       "26   Working knowledge of the Hadoop ecosystem (inc...\n",
       "27   Proficiency in fully architecting and executin...\n",
       "28   Proficiency with Node.js and SQL; Expert profi...\n",
       "29   Experience in machine learning, artificial int...\n",
       "..                                                 ...\n",
       "890  Experience building and optimizing ‘big data’ ...\n",
       "891  Experience performing root cause analysis on i...\n",
       "892  Strong analytic skills related to working with...\n",
       "893  Build processes supporting data transformation...\n",
       "894  A successful history of manipulating, processi...\n",
       "895  Experience supporting and working with cross-f...\n",
       "896  Proficient understanding of distributed comput...\n",
       "897  Develop and update test plans, procedures and ...\n",
       "898  Execute developed test procedures and document...\n",
       "899  Technically coordinate with a cross-functional...\n",
       "900  Maintain and create test scripts, files and da...\n",
       "901  Work in an integrated product team and underst...\n",
       "902  Utilize existing system specifications, interf...\n",
       "903  Ensure that all technical work is performed an...\n",
       "904  Develop test estimates for proposed work and s...\n",
       "905  A Bachelor's degree in Computer Science, Elect...\n",
       "906  Experience in test engineering processes and m...\n",
       "907       Manual, ad hoc, black and white box testing.\n",
       "908  Strong collaboration, organization, teaming an...\n",
       "909  Ability to work well individually or in a grou...\n",
       "910  Ability to work under pressure and time constr...\n",
       "911  Ability to create and deliver technical presen...\n",
       "912              Python or similar scripting language.\n",
       "913  Experience with MIL-STD-1553 data bus, avionic...\n",
       "914  Experience with system security and safety eng...\n",
       "915  Experience with configuration management and r...\n",
       "916  Experience directing small teams of employees ...\n",
       "917                  Test Engineer jobs in Atlanta, GA\n",
       "918  Jobs at Georgia Tech Research Institute in Atl...\n",
       "919              Test Engineer salaries in Atlanta, GA\n",
       "\n",
       "[920 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bullets = pd.read_csv('Bullets')\n",
    "bullets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Strong, out-of-the-box thinking, and a curious mind'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bullets['0'][258]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cvec.fit()` will be expecting a pandas Series of text objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<920x1845 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10192 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec.fit(bullets['0'])\n",
    "new_corpus = cvec.transform(bullets['0'])\n",
    "new_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_corpus.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0064382_p0223181</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>1372</th>\n",
       "      <th>15</th>\n",
       "      <th>1553</th>\n",
       "      <th>2016</th>\n",
       "      <th>24</th>\n",
       "      <th>...</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>www</th>\n",
       "      <th>yarn</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1845 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     000  0064382_p0223181  10  100  12  1372  15  1553  2016  24 ...   \\\n",
       "824    0                 0   0    0   0     0   0     0     0   0 ...    \n",
       "865    0                 0   0    0   0     0   0     0     0   0 ...    \n",
       "841    0                 0   0    0   0     0   0     0     0   0 ...    \n",
       "491    0                 0   0    0   0     0   0     0     0   0 ...    \n",
       "890    0                 0   0    0   0     0   0     0     0   0 ...    \n",
       "609    0                 0   0    0   0     0   0     0     0   0 ...    \n",
       "470    0                 0   0    0   0     0   0     0     0   0 ...    \n",
       "870    0                 0   0    0   0     0   0     0     0   0 ...    \n",
       "868    0                 0   0    0   0     0   0     0     0   0 ...    \n",
       "196    0                 0   0    0   0     0   0     0     0   0 ...    \n",
       "\n",
       "     writing  written  www  yarn  year  years  you  your  yourself  yrs  \n",
       "824        1        0    0     0     0      0    0     0         0    0  \n",
       "865        0        0    0     0     0      0    0     0         0    0  \n",
       "841        0        0    0     0     0      0    0     0         0    0  \n",
       "491        0        0    0     0     0      0    0     0         0    0  \n",
       "890        0        0    0     0     0      0    0     0         0    0  \n",
       "609        0        0    0     0     0      0    0     0         0    0  \n",
       "470        0        0    0     0     0      0    0     0         0    0  \n",
       "870        0        0    0     0     0      0    0     0         0    0  \n",
       "868        0        0    0     0     0      0    0     0         0    0  \n",
       "196        0        0    0     0     0      0    0     0         0    0  \n",
       "\n",
       "[10 rows x 1845 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  = pd.DataFrame(new_corpus.todense(),\n",
    "                   columns=cvec.get_feature_names())\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.sort_values('data', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and            733\n",
       "in             362\n",
       "data           350\n",
       "to             296\n",
       "of             225\n",
       "with           184\n",
       "experience     180\n",
       "the            160\n",
       "or             149\n",
       "ga             125\n",
       "atlanta        108\n",
       "business        83\n",
       "as              82\n",
       "jobs            79\n",
       "scientist       79\n",
       "for             78\n",
       "learning        76\n",
       "science         67\n",
       "machine         64\n",
       "statistical     62\n",
       "engineering     58\n",
       "at              56\n",
       "analysis        55\n",
       "models          55\n",
       "years           54\n",
       "techniques      54\n",
       "skills          52\n",
       "ability         51\n",
       "analytics       50\n",
       "advanced        50\n",
       "              ... \n",
       "lot              1\n",
       "lookup           1\n",
       "looking          1\n",
       "located          1\n",
       "local            1\n",
       "loading          1\n",
       "living           1\n",
       "listing          1\n",
       "listening        1\n",
       "links            1\n",
       "link             1\n",
       "lifetime         1\n",
       "lidar            1\n",
       "leveraged        1\n",
       "learns           1\n",
       "latest           1\n",
       "landscape        1\n",
       "labeling         1\n",
       "kpis             1\n",
       "know             1\n",
       "kafka            1\n",
       "judgment         1\n",
       "journey          1\n",
       "journals         1\n",
       "journal          1\n",
       "joining          1\n",
       "join             1\n",
       "jenkins          1\n",
       "its              1\n",
       "000              1\n",
       "Length: 1845, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'nobody', 'ltd', 'take', 'often', 'fifteen', 'nor', 'thereafter', 'con', 'he', 'thereupon', 'until', 'couldnt', 'seems', 'together', 'now', 'nevertheless', 'am', 'below', 'it', 'eg', 'during', 'those', 'nowhere', 'both', 'for', 'is', 'someone', 'first', 'their', 'wherein', 'you', 'they', 'any', 'anyone', 'but', 'would', 'less', 'except', 'some', 'well', 'alone', 'around', 'give', 'interest', 'almost', 'former', 'there', 'amoungst', 'whom', 'perhaps', 'down', 'wherever', 'itself', 'himself', 'becomes', 'of', 'behind', 'much', 'anyway', 'elsewhere', 'whenever', 'still', 'be', 'although', 'last', 'though', 'two', 'do', 'even', 'thus', 'an', 'hereafter', 'least', 'whereby', 'per', 'are', 'became', 'along', 'anyhow', 'before', 'were', 'cant', 'everywhere', 'thence', 'have', 'whereas', 'seem', 'yourself', 'either', 'third', 'upon', 'toward', 'in', 'to', 'nothing', 'under', 'mine', 'become', 'one', 'keep', 'same', 'its', 'move', 'cannot', 'each', 'hers', 'eight', 'everyone', 'front', 'latterly', 'put', 'already', 'serious', 'sometime', 'system', 'twenty', 'whither', 'hereby', 'without', 'had', 'something', 'beforehand', 'again', 'mill', 'namely', 'please', 'five', 're', 'must', 'could', 'everything', 'yours', 'yourselves', 'your', 'else', 'ever', 'next', 'since', 'towards', 'four', 'another', 'hundred', 'when', 'whereafter', 'what', 'over', 'we', 'why', 'empty', 'meanwhile', 'beyond', 'might', 'out', 'on', 'therefore', 'rather', 'thick', 'which', 'anywhere', 'hereupon', 'whereupon', 'found', 'seeming', 'being', 'besides', 'get', 'hence', 'into', 'ourselves', 'that', 'yet', 'been', 'him', 'her', 'detail', 'back', 'other', 'mostly', 'side', 'after', 'more', 'not', 'full', 'sixty', 'own', 'latter', 'as', 'such', 'anything', 'fill', 'see', 'whose', 'through', 'herself', 'indeed', 'amount', 'only', 'somehow', 'therein', 'forty', 'she', 'has', 'moreover', 'fifty', 'by', 'above', 'co', 'go', 'once', 'ten', 'several', 'or', 'our', 'call', 'with', 'seemed', 'ie', 'name', 'can', 'up', 'how', 'un', 'onto', 'while', 'find', 'noone', 'i', 'twelve', 'because', 'whatever', 'thin', 'neither', 'formerly', 'eleven', 'ours', 'others', 'always', 'part', 'who', 'three', 'most', 'so', 'de', 'amongst', 'enough', 'will', 'becoming', 'among', 'all', 'afterwards', 'made', 'done', 'none', 'further', 'sometimes', 'then', 'thereby', 'thru', 'between', 'inc', 'never', 'them', 'very', 'these', 'whether', 'etc', 'the', 'every', 'at', 'beside', 'via', 'six', 'this', 'show', 'his', 'herein', 'us', 'where', 'due', 'hasnt', 'cry', 'nine', 'a', 'bill', 'many', 'whence', 'across', 'bottom', 'too', 'against', 'off', 'top', 'me', 'may', 'no', 'also', 'fire', 'if', 'myself', 'few', 'sincere', 'themselves', 'whoever', 'whole', 'and', 'within', 'about', 'somewhere', 'my', 'than', 'here', 'otherwise', 'from', 'should', 'throughout', 'describe', 'was', 'however'})\n"
     ]
    }
   ],
   "source": [
    "#clean it up by importing STOP Words\n",
    "\n",
    "from sklearn.feature_extraction import stop_words\n",
    " \n",
    "print(stop_words.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and            733\n",
       "in             362\n",
       "data           350\n",
       "to             296\n",
       "of             225\n",
       "with           184\n",
       "experience     180\n",
       "the            160\n",
       "or             149\n",
       "ga             125\n",
       "atlanta        108\n",
       "business        83\n",
       "as              82\n",
       "jobs            79\n",
       "scientist       79\n",
       "for             78\n",
       "learning        76\n",
       "science         67\n",
       "machine         64\n",
       "statistical     62\n",
       "engineering     58\n",
       "at              56\n",
       "analysis        55\n",
       "models          55\n",
       "years           54\n",
       "techniques      54\n",
       "skills          52\n",
       "ability         51\n",
       "analytics       50\n",
       "advanced        50\n",
       "              ... \n",
       "lot              1\n",
       "lookup           1\n",
       "looking          1\n",
       "located          1\n",
       "local            1\n",
       "loading          1\n",
       "living           1\n",
       "listing          1\n",
       "listening        1\n",
       "links            1\n",
       "link             1\n",
       "lifetime         1\n",
       "lidar            1\n",
       "leveraged        1\n",
       "learns           1\n",
       "latest           1\n",
       "landscape        1\n",
       "labeling         1\n",
       "kpis             1\n",
       "know             1\n",
       "kafka            1\n",
       "judgment         1\n",
       "journey          1\n",
       "journals         1\n",
       "journal          1\n",
       "joining          1\n",
       "join             1\n",
       "jenkins          1\n",
       "its              1\n",
       "000              1\n",
       "Length: 1845, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned up dataframe\n",
    "\n",
    "df.to_csv('Word Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Word Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       422740\n",
       "and                 733\n",
       "in                  362\n",
       "data                350\n",
       "to                  296\n",
       "of                  225\n",
       "with                184\n",
       "experience          180\n",
       "the                 160\n",
       "or                  149\n",
       "ga                  125\n",
       "atlanta             108\n",
       "business             83\n",
       "as                   82\n",
       "scientist            79\n",
       "jobs                 79\n",
       "for                  78\n",
       "learning             76\n",
       "science              67\n",
       "machine              64\n",
       "statistical          62\n",
       "engineering          58\n",
       "at                   56\n",
       "models               55\n",
       "analysis             55\n",
       "techniques           54\n",
       "years                54\n",
       "skills               52\n",
       "ability              51\n",
       "analytics            50\n",
       "                  ...  \n",
       "proofs                1\n",
       "elasticsearch         1\n",
       "propensity            1\n",
       "proactive             1\n",
       "entire                1\n",
       "prioritizing          1\n",
       "preparation           1\n",
       "ppm                   1\n",
       "everyone              1\n",
       "every                 1\n",
       "practicing            1\n",
       "evangelize            1\n",
       "predicting            1\n",
       "prediction            1\n",
       "evaluates             1\n",
       "prefer                1\n",
       "etls                  1\n",
       "prepare               1\n",
       "prioritize            1\n",
       "president             1\n",
       "estimation            1\n",
       "estimates             1\n",
       "establishing          1\n",
       "establish             1\n",
       "essential             1\n",
       "pressure              1\n",
       "price                 1\n",
       "eo                    1\n",
       "prior                 1\n",
       "interpret             1\n",
       "Length: 1846, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
