{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "import seaborn as sns\n",
    "cvec = CountVectorizer(stop_words = stop_words.ENGLISH_STOP_WORDS)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = ['000', '01', '06', '08','10254', '12', '15',\n",
    "                   '19', '2018', '22', '25', '28', '45', '500',\n",
    "                   'cox', 'norfolk', 'apply', 'com', 'www', 'applications', 'application',\n",
    "                   'applicants', 'southern', 'https', 'ia', 'var', 'indeedapply', 'env',\n",
    "                   'atlanta', 'opportunity', 'iip', 'gender', 'location', 'new', 'employer',\n",
    "                   'midtown', 'manheim', 'ml', 'including', 'llc', 'truck', 'automotive', 'nationality', \n",
    "                   'nation', 'iot', 'kelley', 'hopea', 'date', 'incadea', 'honeywell', '100', '1372', '27', '300',\n",
    "                   '30308', '30309', '59', '60', '666', '715', '800', '850', '89', '90', 'ga', 'geo', 'genetic',\n",
    "                    'mercedes', 'marta', 'lunch', 'familimarity', 'fitting', 'floors', 'furthermore', 'living', \n",
    "                    'make', 'members', 'family', 'req149533', 'requisition', 'freshman', 'sophomore', 'et', 'etc',\n",
    "                    'etl', 'job', 'invest', 'member', 'eye', 'relocation', 'Unnamed', 'wework', 'yarn', 'yrs',\n",
    "                    'test', 'intent', 'intermediete', 'key', 'inflection', 'informatica', 'way', 'recent', 'fewer',\n",
    "                    'iteratively', 'joining', 'd3', 'bi', 'bs', 'alteryx', 'benz', 'ai', 'arcgis', 'talend', 'al',\n",
    "                    'bus', 'cassandra', 'growing', 'growth', 'guidance', 'bigdata', 'bigquery', 'cotiviti', \n",
    "                    'councils', 'like', 'located', 'devops', 'usa', 'winning', 'ex', 'awesome', 'address', \n",
    "                    'assurance', 'pig', 'needed', 'id', 'integral', 'impeccable', 'arts', 'auditing', 'community',\n",
    "                    'commuter', 'jobs', 'help', 'js', 'human', 'variety', 'stipend', 'rewards', 'sharting', \n",
    "                    'daimler', 'degreepreferred', 'advisors', 'characteristics', 'draw', 'donor', 'creek', 'dental',\n",
    "                    'medical', 'survival', '0064382_p0223181', '10', '1553', '2016', '24', '30327', '401',\n",
    "                    'experiencepredictive', 'emory', 'caffe2', 'caffe', 'workingmother','000', '01', '06', '08','10254', '12', '15',\n",
    "                    '19', '2018', '22', '25', '28', '45', '500',\n",
    "                    'cox', 'norfolk', 'apply', 'com', 'www', 'applications', 'application',\n",
    "                    'applicants', 'southern', 'https', 'ia', 'var', 'indeedapply', 'env',\n",
    "                    'atlanta', 'opportunity', 'iip', 'gender', 'location', 'new', 'employer',\n",
    "                    'midtown', 'manheim', 'ml', 'including', 'llc', 'truck', 'automotive', 'nationality', \n",
    "                    'nation', 'iot', 'kelley', 'hopea', 'date', 'incadea', 'honeywell', '100', '1372', '27', '300',\n",
    "                    '30308', '30309', '59', '60', '666', '715', '800', '850', '89', '90', 'ga', 'geo', 'genetic',\n",
    "                    'mercedes', 'marta', 'lunch', 'familimarity', 'fitting', 'floors', 'furthermore', 'living', \n",
    "                    'make', 'members', 'family', 'req149533', 'requisition', 'freshman', 'sophomore', 'et', 'etc',\n",
    "                    'etl', 'job', 'invest', 'member', 'eye', 'relocation', 'Unnamed', 'wework', 'yarn', 'yrs',\n",
    "                    'test', 'intent', 'intermediete', 'key', 'inflection', 'informatica', 'way', 'recent', 'fewer',\n",
    "                    'iteratively', 'joining', 'd3', 'bi', 'bs', 'alteryx', 'benz', 'ai', 'arcgis', 'talend', 'al',\n",
    "                    'bus', 'cassandra', 'growing', 'growth', 'guidance', 'bigdata', 'bigquery', 'cotiviti', \n",
    "                    'councils', 'like', 'located', 'devops', 'usa', 'winning', 'ex', 'Location'\n",
    "                   ]\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stop = list(stop_words.ENGLISH_STOP_WORDS)\n",
    "\n",
    "new_stop.extend(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    \"\"\"Takes 2 vectors a, b and returns the cosine similarity according \n",
    "    to the definition of the dot product\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(file):\n",
    "    raw = open(file).read()\n",
    "    tokens = word_tokenize(raw)\n",
    "    words = [w.lower() for w in tokens]\n",
    "    \n",
    "    porter = nltk.PorterStemmer()\n",
    "    stemmed_tokens = [porter.stem(t) for t in words]\n",
    "    \n",
    "   \n",
    "    stop_words = new_stop\n",
    "    filtered_tokens = [w for w in stemmed_tokens if not w in stop_words]\n",
    "    \n",
    "    \n",
    "    count = nltk.defaultdict(int)\n",
    "    for word in filtered_tokens:\n",
    "        count[word] += 1\n",
    "    return count;\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between the two documents you are comparing is 80.65228567560612\n",
      "Similarity between the two documents you are comparing is 80.79171338005364\n",
      "Similarity between the two documents you are comparing is 99.87845258190418\n",
      "Similarity between the two documents you are comparing is 63.15853983031121\n",
      "Similarity between the two documents you are comparing is 63.16388322991382\n",
      "Similarity between the two documents you are comparing is 80.55286724386033\n",
      "Similarity between the two documents you are comparing is 80.76833378221363\n",
      "Similarity between the two documents you are comparing is 65.64816339166467\n",
      "Similarity between the two documents you are comparing is 66.0643347235352\n",
      "Similarity between the two documents you are comparing is 68.6050310746916\n",
      "Similarity between the two documents you are comparing is 68.8635923016198\n",
      "Similarity between the two documents you are comparing is 81.40338226069609\n",
      "Similarity between the two documents you are comparing is 81.65810849626254\n",
      "Similarity between the two documents you are comparing is 82.01789974145953\n",
      "Similarity between the two documents you are comparing is 82.39731688629782\n",
      "Similarity between the two documents you are comparing is 75.70482531688369\n",
      "Similarity between the two documents you are comparing is 76.01716945351929\n",
      "Similarity between the two documents you are comparing is 81.77815169243203\n",
      "Similarity between the two documents you are comparing is 82.05202283817908\n",
      "Similarity between the two documents you are comparing is 60.6415644140976\n",
      "Similarity between the two documents you are comparing is 61.11744432757311\n",
      "Similarity between the two documents you are comparing is 83.26277318524093\n",
      "Similarity between the two documents you are comparing is 84.1112879019486\n",
      "Similarity between the two documents you are comparing is 92.87453705673208\n",
      "Similarity between the two documents you are comparing is 92.85662367186912\n",
      "Similarity between the two documents you are comparing is 89.26826040278203\n",
      "Similarity between the two documents you are comparing is 89.6022736805231\n",
      "Similarity between the two documents you are comparing is 64.841367365343\n",
      "Similarity between the two documents you are comparing is 65.28088677186587\n",
      "Similarity between the two documents you are comparing is 84.33042106515984\n",
      "Similarity between the two documents you are comparing is 84.6748787338342\n",
      "Similarity between the two documents you are comparing is 81.90264332888442\n",
      "Similarity between the two documents you are comparing is 82.30233873692188\n",
      "Similarity between the two documents you are comparing is 86.74786321849109\n",
      "Similarity between the two documents you are comparing is 87.02017212302087\n"
     ]
    }
   ],
   "source": [
    "def get_similarity(dict1, dict2):\n",
    "    all_words_list = []\n",
    "    for key in dict1:\n",
    "        all_words_list.append(key)\n",
    "    for key in dict2:\n",
    "        all_words_list.append(key)\n",
    "    all_words_list_size = len(all_words_list)\n",
    "    \n",
    "    v1 = np.zeros(all_words_list_size, dtype = np.int)\n",
    "    v2 = np.zeros(all_words_list_size, dtype = np.int)\n",
    "    i = 0\n",
    "    for (key) in all_words_list:\n",
    "        v1[i] = dict1.get(key, 0)\n",
    "        v2[i] = dict2.get(key, 0)\n",
    "        i = i + 1\n",
    "    return cos_sim(v1, v2) * 100;\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dict1 = process('Bullets')\n",
    "    dict2 = process('Resumes/Updated_Resume_Vectorized.csv')\n",
    "    dict3 = process('Resumes/Resume_Vectorized.csv')\n",
    "    dict4 = process('Paragraphs')\n",
    "    dict5 = process('Job_Descriptions_csv/TruckIT-Desc.csv')\n",
    "    dict6 = process('Job_Descriptions_csv/Cotiviti.csv')\n",
    "    dict7 = process('Job_Descriptions_csv/HomeDepot.csv')\n",
    "    dict8 = process('Job_Descriptions_csv/Honeywell.csv')\n",
    "    dict9 = process('Job_Descriptions_csv/AnswerRocket.csv')\n",
    "    dict10 = process('Job_Descriptions_csv/Hope Research.csv')\n",
    "    dict11 = process('Job_Descriptions_csv/Cox.csv')\n",
    "    dict12 = process('Job_Descriptions_csv/Equifax.csv')\n",
    "    dict13 = process('Job_Descriptions_csv/Travelport.csv')\n",
    "    dict14 = process('Job_Descriptions_csv/CocaCola.csv')\n",
    "    dict15 = process('Job_Descriptions_csv/SalesLoft.csv')\n",
    "    dict16 = process('Job_Descriptions_csv/Softvision.csv')\n",
    "    dict17 = process('Job_Descriptions_csv/Aarons.csv')\n",
    "    dict18 = process('Job_Descriptions_csv/InspireBrands.csv')\n",
    "    dict19 = process('Job_Descriptions_csv/Hiscox.csv')\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict1, dict2))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict1, dict3))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict3))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict4))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict4))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict5))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict5))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict6))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict6))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict7))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict7))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict8))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict8))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict9))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict9))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict10))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict10))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict11))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict11))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict12))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict12))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict13))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict13))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict14))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict14))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict15))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict15))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict16))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict16))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict17))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict17))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict18))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict18))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict2, dict19))\n",
    "    print(\"Similarity between the two documents you are comparing is\",\n",
    "          get_similarity(dict3, dict19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
